{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Scoring Model - Feature Engineering\n",
    "\n",
    "This notebook performs feature engineering and selection.\n",
    "\n",
    "## Objectives:\n",
    "1. Engineer risk tiers (Low, Medium, High)\n",
    "2. Create derived features\n",
    "3. Encode categorical variables\n",
    "4. Scale numerical features\n",
    "5. Select important features\n",
    "6. Validate engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "from src.utils import load_config\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "\n",
    "print(f\"Data loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Engineer Risk Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "# Engineer risk tiers\n",
    "df_risk = engineer.engineer_risk_tiers(df)\n",
    "\n",
    "print(\"Risk Tier Distribution:\")\n",
    "print(df_risk['risk_tier'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df_risk['risk_tier'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk tier distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "tier_counts = df_risk['risk_tier'].value_counts()\n",
    "colors = {'Low': 'green', 'Medium': 'orange', 'High': 'red'}\n",
    "tier_colors = [colors[tier] for tier in tier_counts.index]\n",
    "\n",
    "axes[0].bar(tier_counts.index, tier_counts.values, color=tier_colors)\n",
    "axes[0].set_title('Risk Tier Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Risk Tier', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(tier_counts.values, labels=tier_counts.index, autopct='%1.1f%%',\n",
    "           colors=[colors[tier] for tier in tier_counts.index], startangle=90)\n",
    "axes[1].set_title('Risk Tier Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between risk tier and loan status\n",
    "if 'loan_status' in df_risk.columns:\n",
    "    cross_tab = pd.crosstab(df_risk['risk_tier'], df_risk['loan_status'], normalize='index') * 100\n",
    "    print(\"Default Rate by Risk Tier:\")\n",
    "    print(cross_tab)\n",
    "    \n",
    "    # Visualize\n",
    "    cross_tab.plot(kind='bar', stacked=False, figsize=(10, 6), color=['green', 'red'])\n",
    "    plt.title('Loan Status by Risk Tier', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Risk Tier', fontsize=12)\n",
    "    plt.ylabel('Percentage (%)', fontsize=12)\n",
    "    plt.legend(['Paid (0)', 'Default (1)'])\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived features\n",
    "df_featured = engineer.create_derived_features(df_risk)\n",
    "\n",
    "print(f\"Features before: {len(df_risk.columns)}\")\n",
    "print(f\"Features after: {len(df_featured.columns)}\")\n",
    "print(f\"New features created: {len(df_featured.columns) - len(df_risk.columns)}\")\n",
    "\n",
    "# Show new features\n",
    "new_features = [col for col in df_featured.columns if col not in df_risk.columns]\n",
    "print(f\"\\nNew features:\")\n",
    "for feat in new_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore some derived features\n",
    "if 'debt_to_income_ratio' in df_featured.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Distribution\n",
    "    axes[0].hist(df_featured['debt_to_income_ratio'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "    axes[0].set_title('Debt-to-Income Ratio Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Debt-to-Income Ratio', fontsize=10)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # By risk tier\n",
    "    df_featured.boxplot(column='debt_to_income_ratio', by='risk_tier', ax=axes[1])\n",
    "    axes[1].set_title('Debt-to-Income Ratio by Risk Tier', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Risk Tier', fontsize=10)\n",
    "    axes[1].set_ylabel('Debt-to-Income Ratio', fontsize=10)\n",
    "    plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical features\n",
    "categorical_cols = df_featured.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Categorical features: {categorical_cols}\")\n",
    "\n",
    "# Encode (using one-hot encoding)\n",
    "df_encoded = engineer.encode_categorical_features(df_featured, method='onehot', fit=True)\n",
    "\n",
    "print(f\"\\nFeatures after encoding: {len(df_encoded.columns)}\")\n",
    "print(f\"Features added: {len(df_encoded.columns) - len(df_featured.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target from features for scaling\n",
    "target_cols = ['risk_tier', 'loan_status', 'risk_tier_encoded']\n",
    "target_cols = [col for col in target_cols if col in df_encoded.columns]\n",
    "\n",
    "# Scale features\n",
    "df_scaled = engineer.scale_numerical_features(df_encoded, method='standard', fit=True, exclude_cols=target_cols)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(f\"\\nSample scaled values (first 5 rows):\")\n",
    "numeric_cols = df_scaled.select_dtypes(include=[np.number]).columns[:5]\n",
    "df_scaled[numeric_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before and after scaling\n",
    "if 'person_income' in df_featured.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Before scaling\n",
    "    axes[0].hist(df_featured['person_income'].dropna(), bins=50, color='coral', edgecolor='black')\n",
    "    axes[0].set_title('Person Income - Before Scaling', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Income', fontsize=10)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=10)\n",
    "    \n",
    "    # After scaling\n",
    "    if 'person_income' in df_scaled.columns:\n",
    "        axes[1].hist(df_scaled['person_income'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "        axes[1].set_title('Person Income - After Scaling', fontsize=12, fontweight='bold')\n",
    "        axes[1].set_xlabel('Scaled Income', fontsize=10)\n",
    "        axes[1].set_ylabel('Frequency', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature selection\n",
    "target_cols = ['risk_tier', 'loan_status', 'risk_tier_encoded']\n",
    "available_targets = [col for col in target_cols if col in df_scaled.columns]\n",
    "\n",
    "feature_cols = [col for col in df_scaled.columns if col not in available_targets]\n",
    "\n",
    "# Select target for feature selection\n",
    "target_col = 'risk_tier_encoded' if 'risk_tier_encoded' in df_scaled.columns else 'loan_status'\n",
    "\n",
    "X = df_scaled[feature_cols]\n",
    "y = df_scaled[target_col]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Target: {target_col}\")\n",
    "print(f\"Samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Mutual Information Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features using mutual information\n",
    "mi_features, mi_scores = engineer.select_features_mutual_info(X, y, k=15)\n",
    "\n",
    "print(f\"Selected {len(mi_features)} features using mutual information\")\n",
    "print(f\"\\nTop 10 features:\")\n",
    "for i, feat in enumerate(mi_features[:10], 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mutual information scores\n",
    "engineer.visualize_feature_importance(\n",
    "    X.columns.tolist(),\n",
    "    mi_scores,\n",
    "    title=\"Mutual Information Scores\",\n",
    "    top_n=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Correlation-Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features\n",
    "corr_features = engineer.select_features_correlation(X, threshold=0.9)\n",
    "\n",
    "print(f\"Features after correlation removal: {len(corr_features)}\")\n",
    "print(f\"Features removed: {len(feature_cols) - len(corr_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Model-Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features using Random Forest\n",
    "rf_features, rf_importances = engineer.select_features_model_based(X, y, k=15)\n",
    "\n",
    "print(f\"Selected {len(rf_features)} features using Random Forest importance\")\n",
    "print(f\"\\nTop 10 features:\")\n",
    "for i, feat in enumerate(rf_features[:10], 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Random Forest feature importance\n",
    "engineer.visualize_feature_importance(\n",
    "    X.columns.tolist(),\n",
    "    rf_importances,\n",
    "    title=\"Random Forest Feature Importance\",\n",
    "    top_n=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Combined Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all selection methods (intersection)\n",
    "final_features = list(set(mi_features) & set(corr_features) & set(rf_features))\n",
    "\n",
    "print(f\"Final selected features: {len(final_features)}\")\n",
    "print(f\"\\nSelected features:\")\n",
    "for i, feat in enumerate(final_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# Visualize overlap\n",
    "from matplotlib_venn import venn3\n",
    "try:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    venn3([set(mi_features), set(rf_features), set(corr_features)],\n",
    "          ('Mutual Info', 'Random Forest', 'Correlation'))\n",
    "    plt.title('Feature Selection Method Overlap', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Note: Install matplotlib-venn to visualize overlap: pip install matplotlib-venn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset with selected features\n",
    "final_cols = final_features + available_targets\n",
    "df_final = df_scaled[final_cols]\n",
    "\n",
    "# Save\n",
    "output_path = '../data/processed/engineered_features.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Engineered features saved to: {output_path}\")\n",
    "print(f\"✓ Final dataset shape: {df_final.shape}\")\n",
    "print(f\"✓ Features: {len(final_features)}\")\n",
    "print(f\"✓ Targets: {len(available_targets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. Original features: {len(df.columns)}\")\n",
    "print(f\"2. After derived features: {len(df_featured.columns)}\")\n",
    "print(f\"3. After encoding: {len(df_encoded.columns)}\")\n",
    "print(f\"4. Final selected features: {len(final_features)}\")\n",
    "\n",
    "print(f\"\\n5. Risk tier distribution:\")\n",
    "if 'risk_tier' in df_final.columns:\n",
    "    print(df_final['risk_tier'].value_counts())\n",
    "elif 'risk_tier_encoded' in df_final.columns:\n",
    "    tier_map = {0: 'Low', 1: 'Medium', 2: 'High'}\n",
    "    print(df_final['risk_tier_encoded'].map(tier_map).value_counts())\n",
    "\n",
    "print(f\"\\n6. Dataset ready for modeling: ✓\")\n",
    "print(f\"   - Train/test split: Next step\")\n",
    "print(f\"   - Model training: Next step\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
